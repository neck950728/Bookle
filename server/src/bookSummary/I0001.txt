컴퓨터는 머신 러닝을 통해 과거의 수집된 데이터를 사용하고, 미래 예측을 하면서, 학습을 진행할 수 있다. 이 책에서는 간단한 예제를 활용해 분류 및 회귀와 같은 통계 학습의 핵심 개념을 직관적으로 확인할 수 있다. 모든 기본 개념을 다룬 후, 의사 결정 트리(Decision tree), 서포트 벡터 머신(Support vector) 및 베이지안(Bayesian) 네트워크와 같은 다양한 알고리즘을 탐색하고 다른 OpenCV 기능과 결합하는 방법을 배우게 된다. 그 과정에서 데이터를 이해하고 어떻게 완벽하게 작동하는 머신 러닝 파이프 라인을 구축 하는지를 이해하여 전체 작업을 배우게 된다. 가장 뜨거운 주제인 '딥러닝'을 시작할 준비가 될 때까지, 더 많은 머신 러닝 기술을 학습할 수 있다. 작업에 적합한 도구를 선택하는 방법을 숙지하고 숙련된 기술과 결합해 모든 관련 머신 러닝의 기본 지식을 파악하게 할 수 있게 된다.
ω
저자 마이클 베이어(Michael Beyeler)는 워싱턴 대학교(University of Washington)의 신경공학 및 데이터 과학 분야 박사후 연구원(Postdoctoral Fellow)으로서 망막 보형물(생체공학적 눈)을 이식받은 맹인 환자의 지각 경험을 향상시키기 위해 생체공학 비전의 컴퓨터 이용 모델을 연구하고 있다. 이 연구는 신경과학, 컴퓨터 공학, 컴퓨터 비전, 머신 러닝의 교차점에 놓여 있다. 고급 컴퓨터 비전 프로젝트를 작성하기 위한 실질적인 가이드로 활용되고 있는 『OpenCV with Python Blueprints』(packt,2015)를 저술했다. 여러 오픈소스 소프트웨어 프로젝트에 적극적으로 참여하고 있으며 파이썬, C/C++, CUDA, MATLAB, 안드로이드와 관련된 전문 프로그래밍 경험을 쌓았다. 
캘리포니아 대학교 어바인(Irvine) 캠퍼스에서 컴퓨터 과학 박사 학위를 받았으며, 스위스 취리히 연방 공과대학교에서 생명공학 석사 학위와 전기공학 학사 학위를 받았다.
ω
1장. 머신 러닝 시작 
__머신 러닝 시작하기 
__머신 러닝으로 해결할 수 있는 문제들 
__파이썬 시작하기 
__OpenCV 시작하기 
__설치하기 
____이 책의 최신 코드 얻기 
____파이썬의 아나콘다 배포판에 대해 살펴보기 
____conda 환경에서 OpenCV 설치 
____설치 확인하기 
____OpenCV의 ML 모듈 엿보기 
__요약 

2장. OpenCV와 파이썬의 데이터 작업 
__머신 러닝 워크플로우의 이해 
__OpenCV와 파이썬을 사용해 데이터 다루기 
____새로운 IPython 또는 주피터 세션 시작하기 
____파이썬 NumPy 패키지를 사용해 데이터 다루기 
____파이썬에서 외부 데이터 세트 적재하기 
____Matplotlib을 사용해 데이터 시각화하기 
____C++에서 OpenCV의 TrainData 컨테이너를 사용해 데이터 다루기 
__요약 

3장. 지도 학습의 첫 번째 단계 
__지도 학습 이해하기 
____OpenCV에서 지도 학습 살펴보기 
____점수화 기능으로 모델 성능 측정 
__분류 모델을 사용해 클래스 레이블 예측하기 
____k-최근접 이웃 알고리즘의 이해 
____OpenCV에서 k-최근접 이웃 구현하기 
__회귀 모델을 사용해 지속적인 결과 예측하기 
____선형 회귀 분석 
____선형 회귀 분석 방법을 사용해 보스턴 주택 가격 예측하 
____라소 및 융기 회귀 적용 
__로지스틱 회귀를 이용한 아이리스 종 분류하기 
____로지스틱 회귀 이해하기 
__요약 

4장. 데이터와 엔지니어링 특징 표현하기 
__특징 엔지니어링의 이해 
__전처리 데이터 
____특징 표준화 
____특징 정규화 
____특징의 범위 확장 
____특징 이진화 
____누락된 데이터 처리 
__차원 축소 이해하기 
____OpenCV에서 PCA 구현하기 
____ICA 구현 
____NMF 구현 
__범주형 변수 표현하기 
__텍스트 특징 표현하기 
__이미지 표현하기 
____색상 공간 사용 
____이미지의 코너 검출하기 
____SIFT 사용하기 
____SURF 사용하기 
__요약 

5장. 의사 결정 트리를 사용해 의료 진단하기 
__의사 결정 트리의 이해 
____첫 번째 결정 트리 만들기 
____훈련된 의사 결정 트리에 대한 시각화 
____의사 결정 트리의 내부 동작 조사 
____특징 중요도 평가 
____의사 결정 규칙 이해하기 
____의사 결정 트리의 복잡성 제어 
__의사 결정 트리를 사용해 유방암 진단하기 
____데이터 세트 불러오기 
____의사 결정 트리 만들기 
__회귀 결정 트리 사용 
__요약 

6장. 서포트 벡터 머신으로 보행자 검출하기 
__선형 서포트 벡터 시스템의 이해 
____최적의 의사 결정 경계 학습 
____첫 번째 서포트 벡터 머신 구현 
__비선형 의사 결정 경계 다루기 
____커널 트릭 이해하기 
____우리가 사용할 커널 파악하기 
____비선형 서포트 벡터 머신 구현 
__외부에서 보행자 검출하기 
____데이터 세트 가져오기 
____HOG 훑어보기 
____네거티브 생성하기 
____서포트 벡터 머신 구현하기 
____모델 부트스트랩하기 
____더 큰 이미지에서 보행자 검출하기 
____모델 개선하기 
__요약 

7장. 베이지안 학습을 이용한 스팸 필터 구현 
__베이지안 추론 이해하기 
____확률 이론에 대해 간단히 살펴보기 
____베이즈 정리 이해하기 
____나이브 베이즈 분류기의 이해 
__첫 번째 베이지안 분류기 구현하기 
____장난감 데이터 세트 만들기 
____일반 베이즈 분류기로 데이터 분류 
__나이브 베이즈 분류기로 데이터 분류하기 
____조건부 확률의 시각화 
____나이브 베이즈 분류기를 사용해 이메일 분류하기 
____데이터 세트 불러오기 
____Pandas를 사용해 데이터 행렬 만들기 
____데이터 전처리하기 
____정상적인 베이즈 분류기 훈련 
____전체 데이터 세트에 대한 교육 
____n-gram을 사용해 결과 개선하기 
____tf-idf를 사용해 결과 개선하기 
__요약 

8장. 비지도 학습으로 숨겨진 구조 발견 
__비지도 학습의 이해 
__k-평균 클러스터링의 이해 
____첫 번째 k-평균 예제 구현 
__기댓값 최대화 방법 이해하기 
____기대치 극대화 솔루션 구현하기 
____기댓값 최대화의 한계 파악하기 
____첫 번째 경고: 전반적인 최적 결과를 찾기 어려움 
____두 번째 경고: 미리 클러스터 수를 선택해야 한다 
____세 번째 주의 사항: 클러스터 경계는 선형이다 
____네 번째 경고: k-평균은 많은 수의 샘플에서는 느리다 
__k-평균을 사용해 색 공간 압축하기 
____트루 컬러 팔레트 시각화 
____k-평균을 사용해 색상 표 축소 
__k-평균을 사용해 숫자 필기 인식 분류하기 
____데이터 세트 불러오기 
____k-평균 실행하기 
__클러스터를 계층적 트리로 구성하기 
____계층적 클러스터링의 이해 
____응집력 있는 계층적 클러스터링 구현 
__요약 

9장. 딥러닝을 사용해 숫자 필기 인식 분류하기 
__맥컬럭-피츠 뉴런에 대한 이해 
__퍼셉트론 이해하기 
__첫 번째 퍼셉트론 구현하기 
____장난감 데이터 세트 생성하기 
____퍼셉트론을 데이터에 적용하기 
____퍼셉트론 분류기 평가 
____선형으로 분리되지 않는 데이터에 퍼셉트론 적용하기 
__다층 퍼셉트론의 이해 
____경사 하강법 이해하기 
____역전파를 이용해 다층 퍼셉트론 훈련하기 
____OpenCV에서 다층 퍼셉트론 구현하기 
__딥러닝에 익숙해지기 
____Keras에 익숙해지기 
__숫자 필기 인식 분류하기 
____MNIST 데이터 세트 적재하기 
____MNIST 데이터 세트 전처리하기 
____OpenCV를 사용해 MLP 훈련하기 
____Keras를 이용한 심층 신경망 훈련하기 
__요약 

10장. 앙상블 기법으로 여러 알고리즘 결합하기 
__앙상블 메소드 이해하기 
____평균 앙상블 이해하기 
____부스터 앙상블 이해하기 
____스태킹 앙상블 이해하기 
__의사 결정 트리를 랜덤 포레스트로 결합하기 
____의사 결정 트리의 단점 이해하기 
____첫 랜덤 포레스트 구현하기 
____scikit-learn을 사용해 랜덤 포레스트 구현하기 
____과랜덤화된 트리 구현하기 
__얼굴 인식을 위한 랜덤 포레스트 사용 
____데이터 세트 불러오기 
____데이터 세트 전처리하기 
____랜덤 포레스트 훈련 및 테스트 
__AdaBoost 구현하기 
____OpenCV에서 AdaBoost 구현하기 
____scikit-learn에서 AdaBoost 구현하기 
__다른 모델을 투표 분류기로 결합하기 
____다양한 투표 방법 이해하기 
____투표 분류기 구현하기 
__요약 

11장. 하이퍼 매개변수 튜닝으로 올바른 모델 선택하기 
__모델 평가하기 
____모델을 잘못된 방식으로 평가하기 
____올바른 방식으로 모델 평가하기 
____최고의 모델 선택하기 
__교차 유효성 검증의 이해 
____OpenCV에서 교차 유효성의 수동 검증 구현 
____k-겹 교차 검증을 위해 scikit-learn 사용하기 
____단일 관측치 제거법 교차 검증 구현 
__부트스트랩을 사용해 견고성 예측하기 
____OpenCV에서 부트스트랩 수동으로 구현하기 
__결과의 중요성 평가하기 
____스튜던트 t-검정 구현하기 
____맥니마의 검정 구현하기 
__격자 검색으로 하이퍼 매개변수 튜닝하기 
____간단한 격자 검색 구현하기 
____유효성 검증 집합의 값 이해하기 
____교차 유효성 검증과 함께 격자 검색 결합하기 
____중첩된 교차 유효성 검증과 함께 격자 검색 결합하기 
__다양한 평가 메트릭을 사용한 점수화 모델 
____올바른 분류 기준 선택하기 
____올바른 회귀 측정 기준 선택하기 
__파이프라인을 형성하기 위한 체이닝 알고리즘 
____scikit-learn에서 파이프라인 구현하기 
____격자 검색의 파이프라인 사용하기 
__요약 

12장. 정리하기 
__머신 러닝 문제점에 접근하기 
__자신만의 추정기 작성하기 
____자신의 OpenCV 기반 분류기를 C++로 작성하기 
____파이썬으로 자신의 scikit-learn 기반 분류기를 작성하기 
__다음 단계 
__요약 